{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f37dbf50",
   "metadata": {},
   "source": [
    "# Experiments for the paper: \"Herding Llamas: Towards Automated Review Title Generation\"\n",
    "\n",
    "- Please ensure you have all dependencies properly configured before attempting to run this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "introductory-building",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import os\n",
    "\n",
    "from rouge import Rouge\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.display import clear_output\n",
    "import language_tool_python\n",
    "\n",
    "import torch\n",
    "from torch import bfloat16\n",
    "import transformers\n",
    "from peft import LoraConfig\n",
    "from transformers import AutoModelForCausalLM, AutoConfig, AutoTokenizer, TrainingArguments, BitsAndBytesConfig\n",
    "from trl import SFTTrainer\n",
    "from datasets import load_dataset\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "tool = language_tool_python.LanguageTool('en-US')\n",
    "module_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\"\n",
    "embed = hub.load(module_url)\n",
    "rouge = Rouge()\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "from utils import process, filtering, filter_by_ratings, duplicate, load_prompts, metrics, MMD, rdiv\n",
    "\n",
    "to_remove = [\"&#34\", \"&quot\", \"<br />\", \"*\", \"/\", \"@\", '\\\\', \"#\", \"%\", \"^\", \"&\", \"~\", \"'\", '\"', '-', '—', '(', ')']\n",
    "punkt = ['.', '?', ';', ':', '!', ',']\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "##################################\n",
    "# cat = 'Automotive'\n",
    "# cat = 'Health_and_Household'\n",
    "# cat = 'Office_Products'\n",
    "cat = 'Arts_Crafts_and_Sewing'\n",
    "oos_cat = 'Arts_Crafts_and_Sewing'\n",
    "##################################\n",
    "\n",
    "try: os.makedirs(cat)\n",
    "except FileExistsError: pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20e8e83",
   "metadata": {},
   "source": [
    "# Import all needed Amazon reviews data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "successful-whale",
   "metadata": {},
   "outputs": [],
   "source": [
    "### WHEN FIRST OPENING THE DATASET ###\n",
    "fivecore = pd.read_csv(os.path.join(cat, cat+'.csv.gz'))\n",
    "dataset = load_dataset(\"McAuley-Lab/Amazon-Reviews-2023\", \"raw_review_\"+cat, split=\"full\", trust_remote_code=True)\n",
    "metadata = load_dataset(\"McAuley-Lab/Amazon-Reviews-2023\", \"raw_meta_\"+cat, split=\"full\", trust_remote_code=True)\n",
    "dataset = dataset.sort(\"parent_asin\")\n",
    "\n",
    "dataset_asins = dataset[\"parent_asin\"]\n",
    "meta_asins = metadata[\"parent_asin\"]\n",
    "\n",
    "_, _, idx = np.intersect1d(dataset_asins, meta_asins, return_indices=True)\n",
    "metadata = metadata.select(idx)\n",
    "meta_asins = metadata[\"parent_asin\"]\n",
    "names = metadata[\"title\"]\n",
    "categories = np.array([', '.join(x) for x in metadata[\"categories\"]])\n",
    "categories[categories == ''] = cat\n",
    "\n",
    "names, categories = duplicate(dataset_asins, meta_asins, names, categories)\n",
    "meta = pd.DataFrame({'title': names, 'categories': categories})\n",
    "meta.to_csv(os.path.join(cat, cat+'_meta.csv.gz'), compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "active-external",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading main data.\n",
      "Getting needed columns.\n"
     ]
    }
   ],
   "source": [
    "### AFTER PROCESSED DATA SAVED ###\n",
    "print(\"Loading main data.\")\n",
    "fivecore = pd.read_csv(os.path.join(cat, cat+'.csv.gz'))\n",
    "dataset = load_dataset(\"McAuley-Lab/Amazon-Reviews-2023\", \"raw_review_\"+cat, split=\"full\", trust_remote_code=True)\n",
    "metadata = pd.read_csv(os.path.join(cat, cat+'_meta.csv.gz'))\n",
    "dataset = dataset.sort(\"parent_asin\")\n",
    "\n",
    "print(\"Getting needed columns.\")\n",
    "titles = dataset['title']\n",
    "reviews = dataset['text']\n",
    "ratings = dataset['rating']\n",
    "times = dataset['timestamp']\n",
    "names = metadata['title']\n",
    "names = np.where(pd.isna(names), cat+' Product', names)\n",
    "categories = metadata['categories']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3befc287",
   "metadata": {},
   "source": [
    "# Filter the dataset based on proposed heuristics (see utils.py):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "lovely-family",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted data point 8966758/8966758. Number of valid review-title pairs: 105244\n"
     ]
    }
   ],
   "source": [
    "# Special case: mismatched reviews need to be removed due to error in dataset\n",
    "exclude = [\n",
    "    \"Meguiar's G191501 Ultimate Snow Foam Wash, Pink Foaming Car Wash Soap for Foam Cannons & Foam Guns, Ideal Foam Wash for Cars, Trucks, Motorcycles, RVs & More - 1 Gallon Container\",\n",
    "    \"Meguiar's Hybrid Wash Mitt, Dual Sided for Washing and Waxing, Clear Coat Safe and Reusable - 1 Mitt\"\n",
    "]\n",
    "\n",
    "start = 0\n",
    "end = None\n",
    "final = filtering(\n",
    "    titles[start:end], \n",
    "    reviews[start:end], \n",
    "    ratings[start:end], \n",
    "    times[start:end], \n",
    "    names[start:end],\n",
    "    categories[start:end],\n",
    "    exclude=exclude\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "comparable-amino",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.DataFrame(final, columns=['title', 'text', 'rating', 'timestamp', 'name', 'category'])\n",
    "final_df.to_csv(os.path.join(cat, 'final.csv'), index=False)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af271ae",
   "metadata": {},
   "source": [
    "# Process the filtered data in various ways:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reverse-tutorial",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates\n",
    "final_new = pd.read_csv(os.path.join(cat, 'final.csv'))\n",
    "\n",
    "final_new.drop_duplicates(subset=['title'], keep='last', inplace=True)\n",
    "final_new.drop_duplicates(subset=['text'], keep='last', inplace=True)\n",
    "\n",
    "titles_new = final_new['title']\n",
    "reviews_new = final_new['text']\n",
    "ratings_new = final_new['rating']\n",
    "times_new = final_new['timestamp']\n",
    "\n",
    "final_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "included-sword",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixing item 103221/103221\n"
     ]
    }
   ],
   "source": [
    "# Fix grammar, spelling, capitalization, and remove extra punctuation from titles.\n",
    "ts = []\n",
    "L = len(titles_new)\n",
    "for idx, (t, r) in enumerate(zip(titles_new, reviews_new)):\n",
    "    clear_output(wait=True)\n",
    "    print('Fixing item {}/{}'.format(idx+1, L))\n",
    "    if t.isupper():\n",
    "        t = t.lower()\n",
    "    t = tool.correct(t)\n",
    "    if t[-1] not in ['.', '?','!']:\n",
    "        t += '.'\n",
    "    extras = ['....', '??','!!','((','))']\n",
    "    replace = ['...', '?', '!', '(', ')']\n",
    "    for _ in range(10):\n",
    "        for _, (e, r) in enumerate(zip(extras, replace)):\n",
    "            t = t.replace(e, r)\n",
    "    ts.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "associate-finnish",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_new['title']=ts\n",
    "final_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "colonial-landscape",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixing item 103221/103221\n"
     ]
    }
   ],
   "source": [
    "# Clean up the reviews a bit\n",
    "rs = []\n",
    "L = len(titles_new)\n",
    "for idx, (t, r) in enumerate(zip(titles_new, reviews_new)):\n",
    "    if idx%100 == 0 or L-idx < 10:\n",
    "        clear_output(wait=True)\n",
    "        print('Fixing item {}/{}'.format(idx+1, L))\n",
    "    rs.append(process(r, [\"&#34\", \"&quot\", \"<br />\"], lower=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "included-blink",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_new['text']=rs\n",
    "final_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minute-truth",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove product reviews if the same product shows up over 5 times in the data.\n",
    "n = ''\n",
    "c = 1\n",
    "idxs = []\n",
    "\n",
    "final_new_idx = final_new.reset_index(drop=True)\n",
    "\n",
    "for idx, row in final_new_idx.iterrows():\n",
    "    if n == row['name']:\n",
    "        c += 1\n",
    "    else:\n",
    "        c = 1\n",
    "        n = row['name']\n",
    "    if c <= 5:\n",
    "        idxs.append(idx)\n",
    "        \n",
    "final_new_idx = final_new_idx.iloc[idxs].reset_index(drop=True)\n",
    "final_new_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "answering-hammer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train/validation/test splits\n",
    "\n",
    "final_new_idx.to_csv(os.path.join(cat, 'final_proc.csv'), index=False)\n",
    "final_proc = pd.read_csv(os.path.join(cat, 'final_proc.csv'))\n",
    "\n",
    "final_train, test_init = train_test_split(final_proc, test_size=0.2)\n",
    "final_valid, final_test = train_test_split(test_init, test_size=0.5)\n",
    "final_train.to_csv(os.path.join(cat, 'final_train.csv'), index=False)\n",
    "final_valid.to_csv(os.path.join(cat, 'final_valid.csv'), index=False)\n",
    "final_test.to_csv(os.path.join(cat, 'final_test.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "animal-distinction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71103 8888 8888\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(os.path.join(cat, 'final_train.csv'))\n",
    "valid = pd.read_csv(os.path.join(cat, 'final_valid.csv'))\n",
    "test = pd.read_csv(os.path.join(cat, 'final_test.csv'))\n",
    "\n",
    "print(len(train), len(valid), len(test))\n",
    "# Automotive: 20202 2525 2526\n",
    "# Health_and_Household: 21328 2666 2666\n",
    "# Office_Products: 22759 2845 2845\n",
    "# Arts_Crafts_and_Sewing: 71103 8888 8888"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bridal-repair",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25145 3035 3125\n"
     ]
    }
   ],
   "source": [
    "# Filter the data one last time to get even numbers of user ratings (1-5)\n",
    "\n",
    "train_even = filter_by_ratings(train)\n",
    "valid_even = filter_by_ratings(valid)\n",
    "test_even = filter_by_ratings(test)\n",
    "\n",
    "train_even.to_csv(os.path.join(cat, 'train_even.csv'), index=False)\n",
    "valid_even.to_csv(os.path.join(cat, 'valid_even.csv'), index=False)\n",
    "test_even.to_csv(os.path.join(cat, 'test_even.csv'), index=False)\n",
    "\n",
    "print(len(train_even), len(valid_even), len(test_even))\n",
    "# Automotive: 6645 720 745 (2M)\n",
    "# Health_and_Household: 7060 815 860 (3M)\n",
    "# Office_Products: 9590 1095 1195 (3M)\n",
    "# Arts_Crafts_and_Sewing: 25145 3035 3125 (all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9c737e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>name</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Not what I expected, but awesome smell.</td>\n",
       "      <td>Was not the product I ordered. Smells divine. ...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1572612599974</td>\n",
       "      <td>The Original CJ's BuTTer (Monkey Farts, 12 oz....</td>\n",
       "      <td>Health &amp; Household, Health Care, Over-the-Coun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bought as a replacement battery for APS backup.</td>\n",
       "      <td>Read another reviewer's suggestion as to what ...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1355167261000</td>\n",
       "      <td>Power-Sonic PS-1290 12 Volt 9 Amp Hour Recharg...</td>\n",
       "      <td>Automotive, Replacement Parts, Batteries &amp; Acc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Does not fit a 2003 1500 at all.</td>\n",
       "      <td>I have a 2003 Dodge Ram 1500 with stock power+...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1646467706564</td>\n",
       "      <td>Fit System K Source 80700 Towing Mirror Ram 15...</td>\n",
       "      <td>Automotive, Exterior Accessories, Towing Produ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Three months--it's ok, but look at the price!</td>\n",
       "      <td>My father purchased this and I'm his tech gal....</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1506447020000</td>\n",
       "      <td>Canon Office Products IP7220 Wireless Color Ph...</td>\n",
       "      <td>Office Products, Office Electronics, Printers ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Great polish for various metals.  Effective an...</td>\n",
       "      <td>I have used this on a variety of metals with g...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1655410569628</td>\n",
       "      <td>Chemical Guys SPI_404_16 Light Metal Polish, 1...</td>\n",
       "      <td>Automotive, Car Care, Exterior Care, Car Polis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2095</th>\n",
       "      <td>Not a Good Label Maker at All!</td>\n",
       "      <td>I always loved making labels like the ones you...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1551814680809</td>\n",
       "      <td>K&amp;CompanySMASH Label Maker</td>\n",
       "      <td>Office Products, Office Electronics, Other Off...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2096</th>\n",
       "      <td>Missing rubber mat &amp; cracked in 1 day?</td>\n",
       "      <td>01/14/2022 The product looks great but it’s mi...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1642197595801</td>\n",
       "      <td>MECHCOS Compatible with 2021 2020 Hyundai Pali...</td>\n",
       "      <td>Automotive, Replacement Parts, Body &amp; Trim, Tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2097</th>\n",
       "      <td>Does NOT FIT Briggs and Stratton 5 gallon plas...</td>\n",
       "      <td>Extremely disappointed when I opened the spout...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1675712510188</td>\n",
       "      <td>CM Concepts U.S Gas/Water Can Long Angled Spou...</td>\n",
       "      <td>Automotive, Motorcycle &amp; Powersports, Parts, F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2098</th>\n",
       "      <td>Does not work with 2020 4RUNNER.</td>\n",
       "      <td>according to AMAZON, this fir my 2020 $RUNNER....</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1660446535093</td>\n",
       "      <td>Rain-X 850012 R16B Expert Fit Rear Blade, (Pac...</td>\n",
       "      <td>Automotive, Replacement Parts, Windshield Wipe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2099</th>\n",
       "      <td>Great portable computer desk for home.</td>\n",
       "      <td>Using it for a portable computer table in my g...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1642715130532</td>\n",
       "      <td>Techni Mobili Rolling Adjustable Laptop Cart, ...</td>\n",
       "      <td>Office Products, Office Furniture &amp; Lighting, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  \\\n",
       "0               Not what I expected, but awesome smell.   \n",
       "1       Bought as a replacement battery for APS backup.   \n",
       "2                      Does not fit a 2003 1500 at all.   \n",
       "3         Three months--it's ok, but look at the price!   \n",
       "4     Great polish for various metals.  Effective an...   \n",
       "...                                                 ...   \n",
       "2095                     Not a Good Label Maker at All!   \n",
       "2096             Missing rubber mat & cracked in 1 day?   \n",
       "2097  Does NOT FIT Briggs and Stratton 5 gallon plas...   \n",
       "2098                   Does not work with 2020 4RUNNER.   \n",
       "2099             Great portable computer desk for home.   \n",
       "\n",
       "                                                   text rating      timestamp  \\\n",
       "0     Was not the product I ordered. Smells divine. ...    4.0  1572612599974   \n",
       "1     Read another reviewer's suggestion as to what ...    4.0  1355167261000   \n",
       "2     I have a 2003 Dodge Ram 1500 with stock power+...    1.0  1646467706564   \n",
       "3     My father purchased this and I'm his tech gal....    3.0  1506447020000   \n",
       "4     I have used this on a variety of metals with g...    5.0  1655410569628   \n",
       "...                                                 ...    ...            ...   \n",
       "2095  I always loved making labels like the ones you...    1.0  1551814680809   \n",
       "2096  01/14/2022 The product looks great but it’s mi...    2.0  1642197595801   \n",
       "2097  Extremely disappointed when I opened the spout...    1.0  1675712510188   \n",
       "2098  according to AMAZON, this fir my 2020 $RUNNER....    2.0  1660446535093   \n",
       "2099  Using it for a portable computer table in my g...    5.0  1642715130532   \n",
       "\n",
       "                                                   name  \\\n",
       "0     The Original CJ's BuTTer (Monkey Farts, 12 oz....   \n",
       "1     Power-Sonic PS-1290 12 Volt 9 Amp Hour Recharg...   \n",
       "2     Fit System K Source 80700 Towing Mirror Ram 15...   \n",
       "3     Canon Office Products IP7220 Wireless Color Ph...   \n",
       "4     Chemical Guys SPI_404_16 Light Metal Polish, 1...   \n",
       "...                                                 ...   \n",
       "2095                         K&CompanySMASH Label Maker   \n",
       "2096  MECHCOS Compatible with 2021 2020 Hyundai Pali...   \n",
       "2097  CM Concepts U.S Gas/Water Can Long Angled Spou...   \n",
       "2098  Rain-X 850012 R16B Expert Fit Rear Blade, (Pac...   \n",
       "2099  Techni Mobili Rolling Adjustable Laptop Cart, ...   \n",
       "\n",
       "                                               category  \n",
       "0     Health & Household, Health Care, Over-the-Coun...  \n",
       "1     Automotive, Replacement Parts, Batteries & Acc...  \n",
       "2     Automotive, Exterior Accessories, Towing Produ...  \n",
       "3     Office Products, Office Electronics, Printers ...  \n",
       "4     Automotive, Car Care, Exterior Care, Car Polis...  \n",
       "...                                                 ...  \n",
       "2095  Office Products, Office Electronics, Other Off...  \n",
       "2096  Automotive, Replacement Parts, Body & Trim, Tr...  \n",
       "2097  Automotive, Motorcycle & Powersports, Parts, F...  \n",
       "2098  Automotive, Replacement Parts, Windshield Wipe...  \n",
       "2099  Office Products, Office Furniture & Lighting, ...  \n",
       "\n",
       "[2100 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine the individual categories into a single, shuffled dataset with even distribution per rating and per category.\n",
    "\n",
    "cats = ['Automotive', 'Health_and_Household', 'Office_Products']\n",
    "amounts = [1000, 140, 140] # 5000 train per category, 700 valid and test per category --> 15000/2100/2100 total\n",
    "names = ['train', 'valid', 'test']\n",
    "\n",
    "for _, (a, n) in enumerate(zip(amounts, names)):\n",
    "    new = []\n",
    "    for c in cats:\n",
    "        current = pd.read_csv(os.path.join(c, n+'_even.csv')).sort_values(by=['rating'])\n",
    "        cols = current.columns\n",
    "        L = len(current)//5\n",
    "        idxs = np.ravel([np.arange(c[0], c[1]) for c in [[L*b,L*b+a] for b in range(5)]])\n",
    "        new.append(current.iloc[idxs,:])\n",
    "    new = pd.DataFrame(np.array(new).reshape(a*15, -1), columns=cols).sample(frac=1).reset_index(drop=True)\n",
    "    new.to_csv(n+'_combined.csv', index=False)  \n",
    "\n",
    "new       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eca65a2",
   "metadata": {},
   "source": [
    "# Load in the model, pipeline, and dataset for training OR evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "usual-blast",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2eab5d2e85804182bb9c096109e24a7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sequence length: 515\n",
      "\n",
      " <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Generate the best succinct title for the following product review. Your only output should be the title itself. Do not mention the user rating in the title. Product rating: 1/5 stars. Product categories: 'Automotive, Interior Accessories, Floor Mats & Cargo Liners, Floor Mats'.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "These are super flimsy and the mats slip and roll around on the floor, can be pretty dangerous when the slip and fold by the pedals. Avoid buying these. Waste of money. You're better off without any mats than having these.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "\"These mats slip, fold, bunch, and roll around your car floor. AVOID.\"<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      " \n",
      "\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Generate the best succinct title for the following product review. Your only output should be the title itself. Do not mention the user rating in the title. Product rating: 4/5 stars. Product categories: 'Health & Household, Health Care, Over-the-Counter Medication, Eczema, Psoriasis & Rosacea Care'.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Was not the product I ordered. Smells divine. I didn't expect it to be derived from nuts and soy, which are two allergens in my family among my children , so I will have to wait to use it. The product I did order did not list those ingredients. But glad to see the smell is still fantastic.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "877f6f2c93604117817f8d6b22d2df23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "##############################################################################################################\n",
    "######################################### USER INPUT ARGS ####################################################\n",
    "##############################################################################################################\n",
    "# model_name = 'meta-llama/Llama-2-7b-chat-hf'\n",
    "model_name = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "\n",
    "base = True # Set to True when fine-tuning OR evaluating a base model\n",
    "evaluate = False # Set to False when fine-tuning\n",
    "use_combined_data = True # Set to True when fine-tuning\n",
    "greedy_sampling = False\n",
    "##############################################################################################################\n",
    "##############################################################################################################\n",
    "##############################################################################################################\n",
    "\n",
    "output_dir = './saves/llama'+('2' if '2' in model_name else '3')\n",
    "if base and evaluate: output_dir += '-base'\n",
    "if use_combined_data and evaluate: output_dir += '-combined'\n",
    "try: os.makedirs(output_dir)\n",
    "except FileExistsError: pass\n",
    "model_dir = os.path.join(output_dir.split('-')[0], 'final')\n",
    "\n",
    "if 'pipeline' in globals(): del pipeline\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=(model_name if base else model_dir),\n",
    "    model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "    device=\"cuda\",\n",
    "    return_full_text=False\n",
    ")\n",
    "\n",
    "prompts_train, prompts_valid, prompts_test = load_prompts(pipeline, (None if use_combined_data else cat))\n",
    "\n",
    "if not evaluate:\n",
    "    # Max sequence length in the dataset (1 token ~ 4 chars)\n",
    "    max_seq = np.max([len(r)//4 for r in prompts_train['text']])\n",
    "    print(\"Max sequence length:\", max_seq)\n",
    "\n",
    "    print('\\n', prompts_train['text'][0], '\\n')\n",
    "    print(prompts_test['text'][0])\n",
    "\n",
    "if (not evaluate) or (not base):\n",
    "    del pipeline\n",
    "\n",
    "# Clear up GPU memory for optimal training and evaluation\n",
    "if 'model' in globals(): del model, tokenizer, bnb, config\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "if base:\n",
    "    config = AutoConfig.from_pretrained(model_name, token=True)\n",
    "    bnb = BitsAndBytesConfig(\n",
    "        load_in_4bit = True,\n",
    "        bnb_4bit_quant_type = 'nf4',\n",
    "        bnb_4bit_use_double_quant = True,\n",
    "        bnb_4bit_compute_dtype = bfloat16\n",
    "    )\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        trust_remote_code = True,\n",
    "        config = config,\n",
    "        quantization_config = bnb,\n",
    "        device_map = 'auto',\n",
    "        token = True\n",
    "    )\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "else:\n",
    "    config = None\n",
    "    bnb = None\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_dir,\n",
    "        torch_dtype=torch.float16\n",
    "    ).to(device)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "\n",
    "model.eval()\n",
    "tokenizer.pad_token = \"[PAD]\"\n",
    "tokenizer.pad_token_id = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c1e9e7",
   "metadata": {},
   "source": [
    "# Train the selected model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "listed-wisconsin",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# TRAIN THE MODEL\n",
    "\n",
    "# Use SFT: Supervised Fine-Tuning\n",
    "# https://github.com/pytorch/torchtune/blob/main/recipes/configs/llama2/7B_qlora_single_device.yaml\n",
    "# https://github.com/pytorch/torchtune/blob/main/recipes/configs/llama3/8B_qlora_single_device.yaml\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    lora_alpha = 16, # 16: The alpha parameter for Lora scaling.\n",
    "    lora_dropout = 0.05, # 0.05:  The dropout probability for Lora layers.\n",
    "    r = 8, # 8: Lora attention dimension (the “rank”).\n",
    "    task_type = \"CAUSAL_LM\"\n",
    ")\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir = output_dir,\n",
    "    per_device_train_batch_size = 2, # 2\n",
    "    gradient_accumulation_steps = 16, # 16,\n",
    "    optim = 'adamw_torch',\n",
    "    weight_decay = 0.01,\n",
    "    save_steps = 100,\n",
    "    logging_steps = 1,\n",
    "    # evaluation_strategy = 'steps',\n",
    "    # eval_steps = 50\n",
    "    learning_rate = 3e-4,\n",
    "    num_train_epochs = 1,\n",
    "    warmup_steps = 100\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    train_dataset = prompts_train,\n",
    "    eval_dataset = prompts_valid,\n",
    "    peft_config = peft_config,\n",
    "    dataset_text_field = 'text',\n",
    "    max_seq_length = 1024,\n",
    "    tokenizer = tokenizer,\n",
    "    args = args,\n",
    ")\n",
    "\n",
    "model.train()\n",
    "trainer.train()\n",
    "trainer.save_model(model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5ef367",
   "metadata": {},
   "source": [
    "# Evaluate the selected model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "thrown-clear",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating sample 3125/3125\n"
     ]
    }
   ],
   "source": [
    "# EVALUATE THE MODEL\n",
    "out = []\n",
    "L = len(prompts_test['text'])\n",
    "\n",
    "for idx, prompt in enumerate(prompts_test['text']):\n",
    "    clear_output(wait=True)\n",
    "    print(\"Evaluating sample {}/{}\".format(idx+1, L))\n",
    "    if base:\n",
    "        if greedy_sampling:\n",
    "            final_outputs = pipeline(prompt, max_new_tokens=30, do_sample=True, top_k=1)\n",
    "        else:\n",
    "            final_outputs = pipeline(prompt, max_new_tokens=30, do_sample=True, temperature=1.0, top_p=0.9)\n",
    "        final_outputs = final_outputs[0]['generated_text'].strip()\n",
    "    else:\n",
    "        inputs = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
    "        if greedy_sampling:\n",
    "            outputs = model.generate(inputs, max_new_tokens=30, do_sample=True, top_k=1)\n",
    "        else:\n",
    "            outputs = model.generate(inputs, max_new_tokens=30, do_sample=True, temperature=1.0, top_p=0.9)\n",
    "        final_outputs = tokenizer.decode(outputs[0])\n",
    "        if '2' in model_dir:\n",
    "            final_outputs = final_outputs.split('[/INST] ')[1].split(' <')[0]\n",
    "        elif '3' in model_dir:\n",
    "            final_outputs = final_outputs.split('t<|end_header_id|>\\n\\n')[1].split('<')[0]\n",
    "    if final_outputs[0] == '\"': final_outputs = final_outputs[1:]\n",
    "    if final_outputs[-1] == '\"': final_outputs = final_outputs[:-1]\n",
    "    out.append(final_outputs)\n",
    "    \n",
    "if greedy_sampling: \n",
    "    np.save(os.path.join(output_dir, 'outputs_greedy.npy'), out)\n",
    "else: \n",
    "    np.save(os.path.join(output_dir, 'outputs_sampled.npy'), out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9121915",
   "metadata": {},
   "source": [
    "# Observe generated titles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italic-mumbai",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# titles = np.load('./saves/llama2/outputs_greedy.npy')\n",
    "# for i, s in enumerate(titles):\n",
    "#     print(i, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52aa14a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# titles = np.load('./saves/llama3/outputs_greedy.npy')\n",
    "# for i, s in enumerate(titles):\n",
    "#     print(i, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775eb216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# titles = np.load('./saves/llama2/outputs_sampled.npy')\n",
    "# for i, s in enumerate(titles):\n",
    "#     print(i, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e9b74b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Works pretty well for toner transfer PCB making.\n",
      "1 Nice but hard to get a thick line.\n",
      "2 Great for adding details to vinyl crafts.\n",
      "3 Great quality and came with 5 sheets.\n",
      "4 These are nice Vipers for a Battlestar Galatica fan.\n",
      "5 Does nothing to stop creaking wood and makes a mess on the floor.\n",
      "6 Disappointing that they are not black ink on one side.\n",
      "7 Bent for Speedweve.\n",
      "8 Great value for the money. I would buy again!\n",
      "9 Good set of fineliners for the price.\n"
     ]
    }
   ],
   "source": [
    "titles = np.load('./saves/llama3/outputs_sampled.npy')\n",
    "for i, s in enumerate(titles[:10]):\n",
    "    print(i, s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fd5eb1",
   "metadata": {},
   "source": [
    "# Calculate Metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36ba0302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing metrics for llama2 greedy\n",
      "Computing metrics for llama2-base greedy\n",
      "Computing metrics for llama2 sampled\n",
      "Computing metrics for llama2-base sampled\n",
      "Computing metrics for llama3 greedy\n",
      "Computing metrics for llama3-base greedy\n",
      "Computing metrics for llama3 sampled\n",
      "Computing metrics for llama3-base sampled\n"
     ]
    }
   ],
   "source": [
    "# Calculate the first set of metrics (see utils.py)\n",
    "\n",
    "for L in ['llama2', 'llama3']:\n",
    "    for S in ['greedy', 'sampled']:\n",
    "        for B in ['', '-base']:\n",
    "            for C in ['']:\n",
    "            # for C in ['', '-combined']:\n",
    "                d = L + B + C\n",
    "                print(\"Computing metrics for\", d, S)\n",
    "                if C == '': test = pd.read_csv(os.path.join(oos_cat, 'test_even.csv'))\n",
    "                else: test = pd.read_csv('test_combined.csv')\n",
    "                gen_titles = np.load('./saves/' + d + '/outputs_{}.npy'.format(S))\n",
    "                ms = metrics(gen_titles, test['text'], test['rating'])\n",
    "                np.save('./saves/' + d + '/metrics_{}.npy'.format(S), ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6561c64c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "llama2-base greedy\n",
      "% Brevity: 93.184\n",
      "% Uniqueness: 90.56\n",
      "% Sentiment: 89.664\n",
      "Average maximum Rouge-1 recall: 0.2625664252767306\n",
      "Average maximum Rouge-2 recall: 0.0864425082398149\n",
      "Average maximum Rouge-L recall: 0.22694859647095786\n",
      "Average maximum similarity: 0.4601032645234466\n",
      "% titles with profanity: 0.576\n",
      "% titles with > 10% special characters: 0.0\n",
      "% titles with emojis (unwanted): 0.0\n",
      "% titles with all uppercase: 0.0\n",
      "\n",
      "llama2 greedy\n",
      "% Brevity: 99.776\n",
      "% Uniqueness: 62.304\n",
      "% Sentiment: 86.048\n",
      "Average maximum Rouge-1 recall: 0.3498470593433228\n",
      "Average maximum Rouge-2 recall: 0.1895903822959325\n",
      "Average maximum Rouge-L recall: 0.3224055083916437\n",
      "Average maximum similarity: 0.536839875767231\n",
      "% titles with profanity: 0.512\n",
      "% titles with > 10% special characters: 0.64\n",
      "% titles with emojis (unwanted): 0.16\n",
      "% titles with all uppercase: 0.064\n",
      "\n",
      "llama3-base greedy\n",
      "% Brevity: 98.592\n",
      "% Uniqueness: 92.512\n",
      "% Sentiment: 87.64800000000001\n",
      "Average maximum Rouge-1 recall: 0.21924827258476812\n",
      "Average maximum Rouge-2 recall: 0.06313255499751581\n",
      "Average maximum Rouge-L recall: 0.19390026322000312\n",
      "Average maximum similarity: 0.4395945113396645\n",
      "% titles with profanity: 0.256\n",
      "% titles with > 10% special characters: 0.0\n",
      "% titles with emojis (unwanted): 0.0\n",
      "% titles with all uppercase: 0.0\n",
      "\n",
      "llama3 greedy\n",
      "% Brevity: 99.80799999999999\n",
      "% Uniqueness: 65.632\n",
      "% Sentiment: 85.536\n",
      "Average maximum Rouge-1 recall: 0.33946686796591935\n",
      "Average maximum Rouge-2 recall: 0.17252501187737543\n",
      "Average maximum Rouge-L recall: 0.31006469752697474\n",
      "Average maximum similarity: 0.5370599107027054\n",
      "% titles with profanity: 0.672\n",
      "% titles with > 10% special characters: 0.512\n",
      "% titles with emojis (unwanted): 0.0\n",
      "% titles with all uppercase: 0.576\n",
      "\n",
      "llama2-base sampled\n",
      "% Brevity: 91.008\n",
      "% Uniqueness: 90.592\n",
      "% Sentiment: 89.44\n",
      "Average maximum Rouge-1 recall: 0.26067910200468913\n",
      "Average maximum Rouge-2 recall: 0.08594858943438254\n",
      "Average maximum Rouge-L recall: 0.22686217418480978\n",
      "Average maximum similarity: 0.4581661443710327\n",
      "% titles with profanity: 0.512\n",
      "% titles with > 10% special characters: 0.0\n",
      "% titles with emojis (unwanted): 0.128\n",
      "% titles with all uppercase: 0.0\n",
      "\n",
      "llama2 sampled\n",
      "% Brevity: 98.336\n",
      "% Uniqueness: 81.984\n",
      "% Sentiment: 82.88\n",
      "Average maximum Rouge-1 recall: 0.29601212099953356\n",
      "Average maximum Rouge-2 recall: 0.11626355131634412\n",
      "Average maximum Rouge-L recall: 0.26642410042289055\n",
      "Average maximum similarity: 0.48420665274381636\n",
      "% titles with profanity: 0.8\n",
      "% titles with > 10% special characters: 1.664\n",
      "% titles with emojis (unwanted): 1.184\n",
      "% titles with all uppercase: 0.32\n",
      "\n",
      "llama3-base sampled\n",
      "% Brevity: 97.824\n",
      "% Uniqueness: 93.504\n",
      "% Sentiment: 87.29599999999999\n",
      "Average maximum Rouge-1 recall: 0.2071666322212863\n",
      "Average maximum Rouge-2 recall: 0.05503958826081858\n",
      "Average maximum Rouge-L recall: 0.18305599081185006\n",
      "Average maximum similarity: 0.42497436252713205\n",
      "% titles with profanity: 0.416\n",
      "% titles with > 10% special characters: 0.0\n",
      "% titles with emojis (unwanted): 0.0\n",
      "% titles with all uppercase: 0.0\n",
      "\n",
      "llama3 sampled\n",
      "% Brevity: 98.56\n",
      "% Uniqueness: 80.224\n",
      "% Sentiment: 84.736\n",
      "Average maximum Rouge-1 recall: 0.29785644970920583\n",
      "Average maximum Rouge-2 recall: 0.11817604267079096\n",
      "Average maximum Rouge-L recall: 0.2681526161374875\n",
      "Average maximum similarity: 0.4912685671318136\n",
      "% titles with profanity: 0.832\n",
      "% titles with > 10% special characters: 0.96\n",
      "% titles with emojis (unwanted): 0.032\n",
      "% titles with all uppercase: 0.32\n"
     ]
    }
   ],
   "source": [
    "# Display the first set of calculated metrics\n",
    "\n",
    "for S in ['greedy', 'sampled']:\n",
    "    for L in ['llama2', 'llama3']:\n",
    "        for B in ['-base', '']:\n",
    "            for C in ['']:\n",
    "            # for C in ['', '-combined']:\n",
    "                d = L + B + C\n",
    "                if C == '': test = pd.read_csv(os.path.join(oos_cat, 'test_even.csv'))\n",
    "                else: test = pd.read_csv('test_combined.csv')\n",
    "                reviews = test['text']\n",
    "                ratings = test['rating']\n",
    "                gen_titles = np.load('./saves/' + d + '/outputs_{}.npy'.format(S))\n",
    "                ms = np.load('./saves/' + d + '/metrics_{}.npy'.format(S))\n",
    "                length = len(ratings)\n",
    "\n",
    "                print('\\n' + d + ' ' + S)\n",
    "                l = ms[:, 0]\n",
    "                print(\"% Brevity:\", 100*(1-(len(l[l<15])+len(l[l>80]))/length))\n",
    "                l = ms[:, 2]\n",
    "                print(\"% Uniqueness:\", 100*len(l[l==0])/length)\n",
    "\n",
    "                count = 0\n",
    "                for _, (pred_sentiment, real_sentiment) in enumerate(zip(ms[:, 7], ms[:, 8])):\n",
    "                    if (pred_sentiment == 0.0 and np.abs(real_sentiment) == 1.0) \\\n",
    "                    or (pred_sentiment < -0.01 and real_sentiment > 0.01) \\\n",
    "                    or (pred_sentiment > 0.01 and real_sentiment < -0.01):\n",
    "                        count += 1\n",
    "                print(\"% Sentiment:\", 100*(1-count/length))\n",
    "\n",
    "                print(\"Average maximum Rouge-1 recall:\", np.mean(ms[:, 3]))\n",
    "                print(\"Average maximum Rouge-2 recall:\", np.mean(ms[:, 4]))\n",
    "                print(\"Average maximum Rouge-L recall:\", np.mean(ms[:, 5]))\n",
    "                print(\"Average maximum similarity:\", np.mean(ms[:, 6]))\n",
    "\n",
    "                l = ms[:, 9]\n",
    "                print(\"% titles with profanity:\", 100*len(l[l==1])/length)\n",
    "                l = ms[:, 10]\n",
    "                print(\"% titles with > 10% special characters:\", 100*len(l[l>0.1])/length)\n",
    "                l = ms[:, 11]\n",
    "                print(\"% titles with emojis (unwanted):\", 100*len(l[l>0])/length)\n",
    "                l = ms[:, 12]\n",
    "                print(\"% titles with all uppercase:\", 100*len(l[l==1])/length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17880c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "llama2-base greedy\n",
      "R-Div: 0.9124214603265018\n",
      "MMD: 0.08716675104704857\n",
      "\n",
      "llama2 greedy\n",
      "R-Div: 0.9713736733054811\n",
      "MMD: 0.024539472817600858\n",
      "\n",
      "llama3-base greedy\n",
      "R-Div: 0.9196652674468246\n",
      "MMD: 0.08809214906296692\n",
      "\n",
      "llama3 greedy\n",
      "R-Div: 0.9757335273801896\n",
      "MMD: 0.024333362718677632\n",
      "\n",
      "llama2-base sampled\n",
      "R-Div: 0.9172515675171973\n",
      "MMD: 0.08599608765064282\n",
      "\n",
      "llama2 sampled\n",
      "R-Div: 0.9876249034603333\n",
      "MMD: 0.013706707859002147\n",
      "\n",
      "llama3-base sampled\n",
      "R-Div: 0.9263676932415199\n",
      "MMD: 0.0864085379602854\n",
      "\n",
      "llama3 sampled\n",
      "R-Div: 0.9911099231822099\n",
      "MMD: 0.013244488271502777\n"
     ]
    }
   ],
   "source": [
    "# Calculate and display MMD and R-Div\n",
    "\n",
    "for S in ['greedy', 'sampled']:\n",
    "    for L in ['llama2', 'llama3']:\n",
    "        for B in ['-base', '']:\n",
    "            for C in ['']:\n",
    "            # for C in ['', '-combined']:\n",
    "                d = L + B + C\n",
    "                if C == '': test = pd.read_csv(os.path.join(oos_cat, 'test_even.csv'))\n",
    "                else: test = pd.read_csv('test_combined.csv')\n",
    "                orig_titles = test['title']\n",
    "                ratings = test['rating']\n",
    "                titles = np.load('./saves/' + d + '/outputs_{}.npy'.format(S))\n",
    "                print('\\n' + d + ' ' + S)\n",
    "                \n",
    "                embs = []\n",
    "                orig_embs = []\n",
    "                for i, (t, ot, rat) in enumerate(zip(titles, orig_titles, ratings)):\n",
    "                    t = process(t, to_remove+punkt)\n",
    "                    ot = process(ot, to_remove+punkt)\n",
    "                    embs.append(embed([t]))\n",
    "                    orig_embs.append(embed([ot]))\n",
    "\n",
    "                embs = np.squeeze(np.array(embs))\n",
    "                orig_embs = np.squeeze(np.array(orig_embs))\n",
    "                # tsne = TSNE(n_components=2, perplexity=10).fit_transform(embs)\n",
    "                # plt.scatter(tsne[:,0], tsne[:,1], c=ratings)\n",
    "\n",
    "                print(\"R-Div:\", rdiv(orig_embs, embs))\n",
    "                print(\"MMD:\", MMD(embs, orig_embs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
